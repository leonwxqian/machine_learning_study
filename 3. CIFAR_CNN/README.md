这次依旧使用CNN来做图像分类。这次分类的是CIFAR-10数据集。

1.使用tensorflow底层API写
===
这个文件夹下有两个工程，均使用tensorflow底层的API（tf.nn）实现。

因CIFAR-10和MNIST类似，因此我使用了MNIST的代码稍作修改以训练它。这次使用的网络结构如下：

复用MNIST的：

`
类型     | Kernel尺寸  | 步长 | 输出尺寸
---------+-------------+------+----------
输入层   |                    | ?x 32x32x3
卷积层1  | 3x3x96      |  1   | ?x 32x32x3x96
池化层1  | 2x2         |  2   | ?x 16x16x3x96
卷积层2  | 5x5x192     |  1   | ?x 16x16x3x192
池化层2  | 2x2         |  2   | ?x 8x8x3x192
全连接层1|                    | ?x 1024
Dropout  |       **0.50**         | ?x 1024
全连接层2|                    | ?x 256
全连接层3|      softmax       | ?x 10
`



为了接收到足够多的信息，在第一个全连接层处，设置神经元数量为1024，且为了平滑过渡到10，在中间加了一层256神经元的全连接层，使用Adam，学习率0.0001，且设置衰减，采用交叉熵作为loss。

因为一次塞入太多样本会直接OOM，所以我将这50000个样本拆成250x200来训练。在最初训练时，我只遍历了250epoch x 每次200个样本便停止，结果每次测试准确率都停留在50%～55%这个区间无法上升。后来在参考别人代码的基础上，开始对样本循环训练，经过2000epoch之后，准确率提到65%～70%左右，和网上大家训练出来的准确率比较接近了。

下面这个神经网络则是我参考
https://stats.stackexchange.com/questions/272607/cifar-10-cant-get-above-60-accuracy-keras-with-tensorflow-backend 的答案改成tensorflow语法的，最终其实和上面的差不多，少了dropout层，准确率也在70%左右，和答主说的“Here's an even simpler and much smaller architecture that can get to 70% pretty quickly with the same training regimen (no BatchNormalization or pooling layers)”类似。
`
类型     | Kernel尺寸  | 步长 | 输出尺寸
---------+-------------+------+----------
输入层   |                    | ?x 32x32x3
卷积层1  | 5x5x64      |  1   | ?x 32x32x3x64
池化层1  | 3x3         |  2   | ?x 16x16x3x64
卷积层2  | 5x5x64      |  1   | ?x 16x16x3x64
池化层2  | 3x3         |  2   | ?x 8x8x3x64
全连接层1|                    | ?x 4096
全连接层2|                    | ?x 384
全连接层3|      softmax       | ?x 10
`
仍然使用Adam，固定学习率0.0001，2000 epoch x 200 样本来训练，没有使用衰减是因为这里我测试似乎固定学习率准确率上升更快，原因未知。另外，去除了dropout因此训练速度也提升很快。但结果和上一个基本是一样的，在1300 epoch左右到达65%附近。2000 epoch能到达70%附近，训练速度也越来越慢。

1.1 准确度优化和网络选择的问题
=======

关于这里准确度的优化，有个说法是应该对图片做一轮变形之类的变换操作，但是我这边是没有做这个步骤的，因此可能会有影响。还有是在训练的过程中，准确度其实并没有收敛到一个值上，而是呈现一个缓慢增长的过程，为了不花费太多时间，我在2000 epoch便结束了训练，后续换了好点的显卡我再试试跑到它稳定为止。

另外，关于准确度的问题，向一个经常做这个的大佬请教了一下，基本就是说，如果没有特殊需求，一般还是应该用那些比较著名的网络结构，只有真的解决不了的时候才应该自己设计网络，因此这里就先这样吧。

1.2 后续记录
=======
（2021.7.7）到此为止的神经网络我都使用的是底层API来写，如果我没看错的话，应该tf也是有封装tf.layers之类的操作的。因此在后面也会加上用上层API实现神经网络的代码。


2.使用tf上层API写
===
（2021.7.8） 这里使用了一些tf封装好的层级结构，例如：
tf.compat.v1.layers.conv2d
tf.layers.dense
来替换原始的卷积层和全连接层，整体网络结构和第一节中的一样，顺便测试无dropout的情况，因此这个工程是没有dropout的。 

不过因为重写了很多网络实现相关的部分，在第一次写完以后训练时成功率一直为0.000，或者卡在非常低的例如0.090左右。 对比原来底层API实现，发现是kernel_initializer没有自动设置导致，设置为使用tf.random_normal_initializer(stddev=0.04)后解决。

调整后，又发现其成功率从epoch 1或者epoch 2开始就一直卡在0.133之类的、相对比较低的数字不变，偶见两个数来回震荡，调整学习率为0.0001后解决。同时加入bias_initializer，与之前的网络结构一致后问题解决，成功率比上一个目录的略低，在65%左右。

3.使用tf.keras写
===
（2021.7.9）这一节试着使用tf.keras，但是稍微修改一下网络结构尝试一下优化（也是因为keras的代码写起来更简单，不用算太多shape）。于是这次在每个池化层之后加入一个dropout。

综合做了三次测试，dropout率分别为0.15, 0.25，0.50，最后发现0.25下表现最佳。

0.50下速度不仅慢，而且训练完准确率只有79%。
0.15下出现了一定的过拟合问题，在训练集上准确率虽然达到了91%，但是测试集上只有84%。

另外，参考书上说的，对图像集合添加增益，以增加模型的稳定性，增加后识别准确率由70%增加到80%以上，同时没有出现过拟合的情况。

以下为0.25的dropout rate，在100轮迭代后达到的准确率是83.91%（训练集82.71%）。
`
1563/1563 [==============================] - 21s 12ms/step - loss: 1.8349 - accuracy: 0.3212 - val_loss: 1.5633 - val_accuracy: 0.4228
Epoch 2/100
1563/1563 [==============================] - 20s 13ms/step - loss: 1.5377 - accuracy: 0.4364 - val_loss: 1.3497 - val_accuracy: 0.5070
Epoch 3/100
1563/1563 [==============================] - 21s 14ms/step - loss: 1.4241 - accuracy: 0.4831 - val_loss: 1.2941 - val_accuracy: 0.5333
Epoch 4/100
…………
Epoch 100/100
1563/1563 [==============================] - 22s 14ms/step - loss: 0.4886 - accuracy: 0.8271 - val_loss: 0.4834 - val_accuracy: 0.8391
`
